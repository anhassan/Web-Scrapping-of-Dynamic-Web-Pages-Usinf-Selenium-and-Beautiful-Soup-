{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Importing Modules*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\programdata\\anaconda2\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda2\\lib\\site-packages (from bs4) (4.6.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grin 1.2.1 requires argparse>=1.1, which is not installed.\n",
      "You are using pip version 10.0.1, however version 20.2.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda2\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda2\\lib\\site-packages (from selenium) (1.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grin 1.2.1 requires argparse>=1.1, which is not installed.\n",
      "You are using pip version 10.0.1, however version 20.2.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install bs4\n",
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Rendering Dynamic Consumer Product Website*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import bs4 as bs\n",
    "\n",
    "PATH = \"C:\\Users\\HP\\Documents\\chromedriver_win32\\chromedriver.exe\"\n",
    "URL = \"https://www.daraz.pk/catalog/?_keyori=ss&from=input&page=1&q=toys&spm=a2a0e.searchlistcategory.search.go.2d162a96soiFLM\"\n",
    "\n",
    "driver = webdriver.Chrome(PATH)\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Scraping Product Features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles , prices , original_prices , sale , discount = [],[],[],[],[]\n",
    "\n",
    "def get_title(product):\n",
    "    return product.find_all('div',class_=\"c16H9d\")[0].find_all('a')[0].get(\"title\")\n",
    "\n",
    "def get_price(product):\n",
    "    return product.find_all('span',class_=\"c13VH6\")[0].text\n",
    "\n",
    "def get_original_price(product):\n",
    "    try:\n",
    "        return product.find_all('del',class_=\"c13VH6\")[0].text\n",
    "    except:\n",
    "        return get_price(product)\n",
    "\n",
    "def get_discount_percent(product):\n",
    "    try:\n",
    "        return product.find_all('span',class_=\"c1hkC1\")[0].text\n",
    "    except:\n",
    "        return '0'\n",
    "\n",
    "def is_sale(product):\n",
    "    try:\n",
    "        return '1' if len(product.find_all('span',class_=\"c1hkC1\")[0].text) >= 1 else '0'\n",
    "    except:\n",
    "        return '0'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Automation with Selenium to span across all pages*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page  1 scrapped....\n",
      "Page  2 scrapped....\n",
      "Page  3 scrapped....\n",
      "Page  4 scrapped....\n",
      "Page  5 scrapped....\n",
      "Page  6 scrapped....\n",
      "Page  7 scrapped....\n",
      "Page  8 scrapped....\n",
      "Page  9 scrapped....\n",
      "Page  10 scrapped....\n",
      "Page  11 scrapped....\n",
      "Page  12 scrapped....\n",
      "Page  13 scrapped....\n",
      "Page  14 scrapped....\n",
      "Page  15 scrapped....\n",
      "Page  16 scrapped....\n",
      "Page  17 scrapped....\n",
      "Page  18 scrapped....\n",
      "Page  19 scrapped....\n",
      "Page  20 scrapped....\n",
      "Page  21 scrapped....\n",
      "Page  22 scrapped....\n",
      "Page  23 scrapped....\n",
      "Page  24 scrapped....\n",
      "Page  25 scrapped....\n",
      "Page  26 scrapped....\n",
      "Page  27 scrapped....\n",
      "Page  28 scrapped....\n",
      "Page  29 scrapped....\n",
      "Page  30 scrapped....\n",
      "Page  31 scrapped....\n",
      "Page  32 scrapped....\n",
      "Page  33 scrapped....\n",
      "Page  34 scrapped....\n",
      "Page  35 scrapped....\n",
      "Page  36 scrapped....\n",
      "Page  37 scrapped....\n",
      "Page  38 scrapped....\n",
      "Page  39 scrapped....\n",
      "Page  40 scrapped....\n",
      "Page  41 scrapped....\n",
      "Page  42 scrapped....\n",
      "Page  43 scrapped....\n",
      "Page  44 scrapped....\n",
      "Page  45 scrapped....\n",
      "Page  46 scrapped....\n",
      "Page  47 scrapped....\n",
      "Page  48 scrapped....\n",
      "Page  49 scrapped....\n",
      "Page  50 scrapped....\n",
      "All pages scrapped successfully...\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "\n",
    "titles , prices , original_prices , sale , discount = [],[],[],[],[]\n",
    "DELAY , MAX_PAGE_LIMIT = 20,50\n",
    "count = 1 \n",
    "\n",
    "\n",
    "for page_num in range(MAX_PAGE_LIMIT):\n",
    "            try:\n",
    "                soup = bs.BeautifulSoup(driver.page_source,'lxml')\n",
    "                product_containers = soup.find_all('div',class_=\"c3e8SH\")\n",
    "                \n",
    "                for product in product_containers:\n",
    "                        titles.append(get_title(product))\n",
    "                        prices.append(get_price(product))\n",
    "                        original_prices.append(get_original_price(product))\n",
    "                        discount.append(get_discount_percent(product))\n",
    "                        sale.append(is_sale(product))\n",
    "                \n",
    "                print \"Page \", count, \"scrapped....\"\n",
    "                next_link = WebDriverWait(driver, DELAY).until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'li.ant-pagination-next')))\n",
    "                next_link.click()\n",
    "                time.sleep(0.5)\n",
    "                driver.get(driver.current_url)\n",
    "                count = count + 1\n",
    "                \n",
    "            except NoSuchElementException:\n",
    "                print \"All pages successfully scrapped....\"\n",
    "\n",
    "print(\"All pages scrapped successfully...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Data Transformation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation_numerical(data):\n",
    "    return [int(re.findall(r'\\d+',val.encode(\"utf-8\"))[0])  for val in data]\n",
    "\n",
    "def data_transformation_textual(data):\n",
    "    return [val.encode(\"utf-8\") for val in data]\n",
    "    \n",
    "\n",
    "prices_transformed = data_transformation_numerical(prices)\n",
    "original_prices_transformed = data_transformation_numerical(original_prices)\n",
    "discount_transformed = data_transformation_numerical(discount)\n",
    "titles_transformed = data_transformation_textual(titles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Tabulating Processed Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sale</th>\n",
       "      <th>Original Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Three In One (Jigsaw+Coloring Pages+Water Colo...</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tool set, 17 pieces (case)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pack Of 10 Toys Of Kitchen set For Kids Best Q...</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kids Remote Control Car</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pack Of -14 Pcs Mini Coffee Set Toy For Kids w...</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Price Sale  \\\n",
       "0  Three In One (Jigsaw+Coloring Pages+Water Colo...    240    0   \n",
       "1                         Tool set, 17 pieces (case)      1    1   \n",
       "2  Pack Of 10 Toys Of Kitchen set For Kids Best Q...    149    1   \n",
       "3                            Kids Remote Control Car    199    1   \n",
       "4  Pack Of -14 Pcs Mini Coffee Set Toy For Kids w...     99    1   \n",
       "\n",
       "   Original Price  Discount  \n",
       "0             240         0  \n",
       "1               2        32  \n",
       "2             400        63  \n",
       "3             250        20  \n",
       "4             150        34  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_scrapped = pd.DataFrame(list(zip(titles_transformed, prices_transformed,sale,original_prices_transformed,discount_transformed)), \n",
    "               columns =['Title', 'Price','Sale','Original Price','Discount'])\n",
    "data_scrapped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Exporting Features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "FILE_NAME = 'data_scrapped.csv'\n",
    "DIRECTORY = \"C:\\Users\\HP\\Documents\\chromedriver_win32\"\n",
    "\n",
    "if not os.path.exists(DIRECTORY):\n",
    "    os.mkdir(DIRECTORY)\n",
    "\n",
    "OUTPUT_FILE_PATH = os.path.join(DIRECTORY, FILE_NAME)    \n",
    "data_scrapped.to_csv(OUTPUT_FILE_PATH,index=False,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
